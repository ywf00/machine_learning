{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyPblAQ+dYFD1f3lPHFdaAFg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"hTqpj6yqTrl_","executionInfo":{"status":"ok","timestamp":1661878494833,"user_tz":-330,"elapsed":2869,"user":{"displayName":"Amrutha Aneesh","userId":"05355874845511060324"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import SGD\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","source":["class BasicNN(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n","    self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n","    self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n","\n","    self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n","    self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n","    self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n","\n","    self.final_bias = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n"],"metadata":{"id":"4tPbQlZhVCRs","executionInfo":{"status":"ok","timestamp":1661878498610,"user_tz":-330,"elapsed":604,"user":{"displayName":"Amrutha Aneesh","userId":"05355874845511060324"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def forward(self, input):\n","  input_to_top_relu = input * self.w00 +self.b00\n","  top_relu_output = F.relu(input_to_top_relu)\n","  scaled_top_relu_output = top_relu_output *self.w01\n","\n","  input_to_bottom_relu = input * self.w10 +self.b10\n","  bottom_relu_output = F.relu(input_to_bottom_relu)\n","  scaled_bottom_relu_output = bottom_relu_output *self.w11\n","\n","  input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n","  output = F.relu(input_to_final_relu)\n","  return output"],"metadata":{"id":"mgBRJ6E0VQap","executionInfo":{"status":"ok","timestamp":1661878502292,"user_tz":-330,"elapsed":5,"user":{"displayName":"Amrutha Aneesh","userId":"05355874845511060324"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["input_doses = torch.linspace(start=0, end=1, steps=11)\n","input_doses"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"869arWSzNVGu","executionInfo":{"status":"ok","timestamp":1661878508457,"user_tz":-330,"elapsed":21,"user":{"displayName":"Amrutha Aneesh","userId":"05355874845511060324"}},"outputId":"d971039e-6a1c-489c-ded4-714d44dbac59"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n","        0.9000, 1.0000])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["model = BasicNN()\n","\n","output_values = model(input_doses)\n","\n","sns.set(style=\"whitegrid\")\n","sns.lineplot(x=input_doses,\n","             y=output_values,\n","             color='green',\n","             linewidth=2.5)\n","plt.ylabel('Effectiveness')\n","plt.xlabel('Dose')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"pWZJkVFzNstg","executionInfo":{"status":"error","timestamp":1661878561849,"user_tz":-330,"elapsed":23,"user":{"displayName":"Amrutha Aneesh","userId":"05355874845511060324"}},"outputId":"2434c37f-df6e-413f-9c6d-bfdc885dc871"},"execution_count":11,"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-fd04f44cb844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_doses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"whitegrid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Module [{type(self).__name__}] is missing the required \\\"forward\\\" function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: Module [BasicNN] is missing the required \"forward\" function"]}]}]}